import torch
import torch.nn as nn
import torch.nn.functional as F


class DoubleConv(nn.Module):
    """(Conv â†’ BN â†’ ReLU) Ã— 2"""
    def __init__(self, in_ch, out_ch):
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),
            nn.BatchNorm2d(out_ch),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),
            nn.BatchNorm2d(out_ch),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        return self.net(x)


# -------------------------------------------------------------
# Flexible U-Net (supports asymmetric pruning)
# -------------------------------------------------------------
class UNet(nn.Module):
    """
    Flexible U-Net that supports asymmetric encoder/decoder pruning.

    Args:
        in_ch (int): Input channels (e.g., 1 for grayscale, 3 for RGB).
        out_ch (int): Output channels (e.g., number of segmentation classes).
        enc_features (list[int]): Encoder block output channels.
        dec_features (list[int], optional): Decoder block output channels.
            If None, defaults to reversed enc_features.
        bottleneck_out (int, optional): Bottleneck output channels.
            If None, defaults to enc_features[-1] * 2.
    """
    def __init__(self,
                 in_ch=1,
                 out_ch=1,
                 enc_features=(32, 64, 128, 256),
                 dec_features=None,
                 bottleneck_out=None):
        super().__init__()

        # ---------- Encoder ----------
        self.encoders = nn.ModuleList()
        prev_ch = in_ch
        for feat in enc_features:
            self.encoders.append(DoubleConv(prev_ch, feat))
            prev_ch = feat

        # ---------- Bottleneck ----------
        if bottleneck_out is None:
            bottleneck_out = enc_features[-1] * 2
        self.bottleneck = DoubleConv(enc_features[-1], bottleneck_out)

        # ---------- Decoder ----------
        if dec_features is None:
            dec_features = list(reversed(enc_features))

        self.decoders = nn.ModuleList()
        prev_ch = bottleneck_out

        for i, feat in enumerate(dec_features):
            # Skip connection channel count (mirror encoder)
            skip_ch = enc_features[-(i + 1)]

            # Upsampling layer
            self.decoders.append(
                nn.ConvTranspose2d(prev_ch, feat, kernel_size=2, stride=2)
            )

            # After concatenation: skip + upsampled feature map
            in_ch_dec = skip_ch + feat
            self.decoders.append(DoubleConv(in_ch_dec, feat))

            prev_ch = feat  # update for next decoder block

        # ---------- Final convolution ----------
        self.final_conv = nn.Conv2d(dec_features[-1], out_ch, kernel_size=1)
        self.pool = nn.MaxPool2d(2)

        # ---------- Channel summary (for debugging / verification) ----------
        print("\nðŸ§© U-Net Architecture Summary:")
        print(f"Input channels:  {in_ch}")
        for i, feat in enumerate(enc_features):
            print(f"Encoder {i+1:<2}: in={in_ch if i==0 else enc_features[i-1]:<4} â†’ out={feat}")
        print(f"Bottleneck : in={enc_features[-1]:<4} â†’ out={bottleneck_out}")
        for i, feat in enumerate(dec_features):
            skip_ch = enc_features[-(i + 1)]
            up_ch = bottleneck_out if i == 0 else dec_features[i - 1]
            print(f"Decoder {i+1:<2}: skip={skip_ch:<4} + up={up_ch:<4} â†’ out={feat}")
        print(f"Output conv: {dec_features[-1]} â†’ {out_ch}\n")



    # ---------- Forward ----------
    def forward(self, x):
        skip_connections = []

        # Encoder path
        for enc in self.encoders:
            x = enc(x)
            skip_connections.append(x)
            x = self.pool(x)

        # Bottleneck
        x = self.bottleneck(x)
        skip_connections = skip_connections[::-1]

        # Decoder path
        for idx in range(0, len(self.decoders), 2):
            x = self.decoders[idx](x)  # ConvTranspose2d (upsample)
            skip = skip_connections[idx // 2]

            # Handle small mismatches (due to pooling/upsampling)
            if x.shape[2:] != skip.shape[2:]:
                x = F.interpolate(x, size=skip.shape[2:], mode="bilinear", align_corners=False)

            # Concatenate skip connection
            x = torch.cat((skip, x), dim=1)

            # DoubleConv
            x = self.decoders[idx + 1](x)

        return torch.sigmoid(self.final_conv(x))


# class UNet(nn.Module):
#     """
#     Flexible U-Net that supports asymmetric encoder/decoder pruning.

#     Args:
#         in_ch (int): input channels (e.g. 1 for grayscale, 3 for RGB)
#         out_ch (int): output channels (e.g. number of segmentation classes)
#         enc_features (list[int] | tuple[int]): encoder block output channels
#         dec_features (list[int] | tuple[int], optional): decoder block output channels.
#             If None, defaults to reversed enc_features.
#         bottleneck_out (int, optional): number of channels in bottleneck output.
#             If None, defaults to enc_features[-1] * 2.
#     """
#     def __init__(self,
#                  in_ch=1,
#                  out_ch=1,
#                  enc_features=(32, 64, 128, 256),
#                  dec_features=None,
#                  bottleneck_out=None):
#         super().__init__()

#         # ---------- Encoder ----------
#         self.encoders = nn.ModuleList()
#         prev_ch = in_ch
#         for feat in enc_features:
#             self.encoders.append(DoubleConv(prev_ch, feat))
#             prev_ch = feat

#         # ---------- Bottleneck ----------
#         if bottleneck_out is None:
#             bottleneck_out = enc_features[-1] * 2
#         self.bottleneck = DoubleConv(enc_features[-1], bottleneck_out)

#         # ---------- Decoder ----------
#         # If not provided, assume symmetric reversed encoder
#         if dec_features is None:
#             dec_features = list(reversed(enc_features))

#         self.decoders = nn.ModuleList()
#         prev_ch = bottleneck_out
#         for feat in dec_features:
#             # upsample: previous block output â†’ current block input
#             self.decoders.append(
#                 nn.ConvTranspose2d(prev_ch, feat, kernel_size=2, stride=2)
#             )
#             # after concatenation, input doubles in channels (skip + upsampled)
#             self.decoders.append(DoubleConv(feat * 2, feat))
#             prev_ch = feat

#         # ---------- Final layer ----------
#         self.final_conv = nn.Conv2d(dec_features[-1], out_ch, kernel_size=1)
#         self.pool = nn.MaxPool2d(2)

#     # ---------- Forward ----------
#     def forward(self, x):
#         skip_connections = []

#         # Encoder pathway
#         for enc in self.encoders:
#             x = enc(x)
#             skip_connections.append(x)
#             x = self.pool(x)

#         # Bottleneck
#         x = self.bottleneck(x)
#         skip_connections = skip_connections[::-1]

#         # Decoder pathway
#         for idx in range(0, len(self.decoders), 2):
#             x = self.decoders[idx](x)  # ConvTranspose2d (upsample)
#             skip = skip_connections[idx // 2]

#             # In case of small rounding mismatches after pooling/upsampling
#             if x.shape[2:] != skip.shape[2:]:
#                 x = F.interpolate(x, size=skip.shape[2:], mode="bilinear", align_corners=False)

#             x = torch.cat((skip, x), dim=1)
#             x = self.decoders[idx + 1](x)  # DoubleConv

#         return torch.sigmoid(self.final_conv(x))


# class DoubleConv(nn.Module):
#     """(Conv â†’ BN â†’ ReLU) Ã— 2"""
#     def __init__(self, in_ch, out_ch):
#         super().__init__()
#         self.net = nn.Sequential(
#             nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),
#             nn.BatchNorm2d(out_ch),
#             nn.ReLU(inplace=True),
#             nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),
#             nn.BatchNorm2d(out_ch),
#             nn.ReLU(inplace=True)
#         )

#     def forward(self, x):
#         return self.net(x)


# class UNet(nn.Module):
#     def __init__(self, in_ch=1, out_ch=1, features=(32, 64, 128, 256)):
#         super().__init__()
#         self.encoders = nn.ModuleList()
#         self.decoders = nn.ModuleList()

#         # Encoder
#         for feat in features:
#             self.encoders.append(DoubleConv(in_ch, feat))
#             in_ch = feat

#         # Bottleneck
#         self.bottleneck = DoubleConv(features[-1], features[-1]*2)

#         # Decoder
#         for feat in reversed(features):
#             self.decoders.append(
#                 nn.ConvTranspose2d(feat*2, feat, kernel_size=2, stride=2)
#             )
#             self.decoders.append(DoubleConv(feat*2, feat))

#         self.final_conv = nn.Conv2d(features[0], out_ch, kernel_size=1)
#         self.pool = nn.MaxPool2d(2)

#     def forward(self, x):
#         skip_connections = []
#         for enc in self.encoders:
#             x = enc(x)
#             skip_connections.append(x)
#             x = self.pool(x)

#         x = self.bottleneck(x)
#         skip_connections = skip_connections[::-1]

#         for idx in range(0, len(self.decoders), 2):
#             x = self.decoders[idx](x)  # upconv
#             skip = skip_connections[idx//2]
#             if x.shape != skip.shape:
#                 x = F.interpolate(x, size=skip.shape[2:])
#             x = torch.cat((skip, x), dim=1)
#             x = self.decoders[idx+1](x)

#         return torch.sigmoid(self.final_conv(x))
