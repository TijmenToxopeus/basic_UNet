{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba80d704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Added project root to sys.path:\n",
      "   /media/ttoxopeus/basic_UNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/ttoxopeus/miniconda3/envs/nnunet/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "PROJECT_ROOT = \"/media/ttoxopeus/basic_UNet\"\n",
    "\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.append(PROJECT_ROOT)\n",
    "    print(f\"‚úÖ Added project root to sys.path:\\n   {PROJECT_ROOT}\")\n",
    "else:\n",
    "    print(f\"‚ÑπÔ∏è Project root already in sys.path:\\n   {PROJECT_ROOT}\")\n",
    "\n",
    "\n",
    "from src.training.eval import evaluate\n",
    "from src.models.unet import UNet\n",
    "from src.pruning.model_inspect import model_to_dataframe_with_l1, get_pruning_masks_blockwise, compute_actual_prune_ratios, compute_l1_norms, compute_l1_stats\n",
    "from src.pruning.rebuild import rebuild_pruned_unet, find_prev_conv_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f100712d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Evaluation on baseline model!\n",
      "üìä Mean Dice: 0.8163\n",
      "üìä Mean IoU:  0.7528\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Background    Dice=0.9974  IoU=0.9949\n",
      "RV            Dice=0.7623  IoU=0.7062\n",
      "Myocardium    Dice=0.8062  IoU=0.7186\n",
      "LV            Dice=0.8805  IoU=0.8337\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n"
     ]
    }
   ],
   "source": [
    "# # Create baseline model\n",
    "# model = UNet(in_ch=1, out_ch=4, enc_features=[64, 128, 256, 512])\n",
    "# df = model_to_dataframe_with_l1(model, remove_nan_layers=True)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# display(df)\n",
    "\n",
    "# 1Ô∏è‚É£ Create model\n",
    "model = UNet(in_ch=1, out_ch=4, enc_features=[64, 128, 256, 512, 512])\n",
    "state = torch.load(\"/media/ttoxopeus/basic_UNet/results/UNet_ACDC/exp41/baseline/training/final_model.pth\", map_location=\"cpu\")\n",
    "model.load_state_dict(state)\n",
    "model.eval()\n",
    "\n",
    "# Path to your metrics file\n",
    "metrics_path = \"/media/ttoxopeus/basic_UNet/results/UNet_ACDC/exp41/baseline/evaluation/eval_metrics.json\"\n",
    "\n",
    "# Load JSON\n",
    "with open(metrics_path, \"r\") as f:\n",
    "    metrics = json.load(f)\n",
    "\n",
    "# Extract values\n",
    "mean_dice_fg = metrics[\"mean_dice_fg\"]\n",
    "mean_iou_fg = metrics[\"mean_iou_fg\"]\n",
    "per_class = metrics[\"per_class\"]\n",
    "\n",
    "# Print formatted output\n",
    "print(\"‚úÖ Evaluation on baseline model!\")\n",
    "print(f\"üìä Mean Dice: {mean_dice_fg:.4f}\")\n",
    "print(f\"üìä Mean IoU:  {mean_iou_fg:.4f}\")\n",
    "print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\")\n",
    "\n",
    "for class_name, vals in per_class.items():\n",
    "    print(f\"{class_name:12s}  Dice={vals['dice_mean']:.4f}  IoU={vals['iou_mean']:.4f}\")\n",
    "\n",
    "print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfc23b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer</th>\n",
       "      <th>Type</th>\n",
       "      <th>Shape</th>\n",
       "      <th>In Ch</th>\n",
       "      <th>Out Ch</th>\n",
       "      <th>Num Params</th>\n",
       "      <th>Mean L1</th>\n",
       "      <th>Min L1</th>\n",
       "      <th>Max L1</th>\n",
       "      <th>L1 Std</th>\n",
       "      <th>Block Ratio</th>\n",
       "      <th>Post-Prune Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>encoders.0.net.0</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(64, 1, 3, 3)</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>576</td>\n",
       "      <td>1.551331</td>\n",
       "      <td>0.941511</td>\n",
       "      <td>2.025421</td>\n",
       "      <td>0.252934</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>encoders.0.net.3</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(64, 64, 3, 3)</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>36864</td>\n",
       "      <td>20.288008</td>\n",
       "      <td>14.836420</td>\n",
       "      <td>26.348740</td>\n",
       "      <td>2.820510</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>encoders.1.net.0</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(128, 64, 3, 3)</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>73728</td>\n",
       "      <td>20.560497</td>\n",
       "      <td>13.653543</td>\n",
       "      <td>29.073994</td>\n",
       "      <td>4.398217</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>encoders.1.net.3</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(128, 128, 3, 3)</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>147456</td>\n",
       "      <td>32.678024</td>\n",
       "      <td>21.367718</td>\n",
       "      <td>49.799278</td>\n",
       "      <td>6.812839</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>encoders.2.net.0</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(256, 128, 3, 3)</td>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>294912</td>\n",
       "      <td>34.095963</td>\n",
       "      <td>20.778049</td>\n",
       "      <td>52.540321</td>\n",
       "      <td>6.267731</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>encoders.2.net.3</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(256, 256, 3, 3)</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>589824</td>\n",
       "      <td>64.204262</td>\n",
       "      <td>35.262543</td>\n",
       "      <td>92.003357</td>\n",
       "      <td>13.836428</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>encoders.3.net.0</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(512, 256, 3, 3)</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>1179648</td>\n",
       "      <td>68.175964</td>\n",
       "      <td>34.533218</td>\n",
       "      <td>98.012207</td>\n",
       "      <td>13.933917</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>encoders.3.net.3</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(512, 512, 3, 3)</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>2359296</td>\n",
       "      <td>124.219528</td>\n",
       "      <td>53.179050</td>\n",
       "      <td>185.167419</td>\n",
       "      <td>25.643438</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>encoders.4.net.0</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(512, 512, 3, 3)</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>2359296</td>\n",
       "      <td>157.922775</td>\n",
       "      <td>100.266998</td>\n",
       "      <td>218.526779</td>\n",
       "      <td>16.962074</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>encoders.4.net.3</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(512, 512, 3, 3)</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>2359296</td>\n",
       "      <td>157.622177</td>\n",
       "      <td>109.752975</td>\n",
       "      <td>203.895996</td>\n",
       "      <td>16.077797</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bottleneck.net.0</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(1024, 512, 3, 3)</td>\n",
       "      <td>512</td>\n",
       "      <td>1024</td>\n",
       "      <td>4718592</td>\n",
       "      <td>144.267090</td>\n",
       "      <td>101.880554</td>\n",
       "      <td>178.879700</td>\n",
       "      <td>14.665365</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bottleneck.net.3</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(1024, 1024, 3, 3)</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>9437184</td>\n",
       "      <td>223.883591</td>\n",
       "      <td>106.554153</td>\n",
       "      <td>386.406921</td>\n",
       "      <td>57.562244</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>decoders.0</td>\n",
       "      <td>ConvTranspose2d</td>\n",
       "      <td>(1024, 512, 2, 2)</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>2097664</td>\n",
       "      <td>44.556839</td>\n",
       "      <td>25.305153</td>\n",
       "      <td>105.051765</td>\n",
       "      <td>13.880632</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>decoders.1.net.0</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(512, 1024, 3, 3)</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>4718592</td>\n",
       "      <td>238.616776</td>\n",
       "      <td>123.579475</td>\n",
       "      <td>373.426453</td>\n",
       "      <td>47.908344</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>decoders.1.net.3</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(512, 512, 3, 3)</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>2359296</td>\n",
       "      <td>124.202682</td>\n",
       "      <td>67.089867</td>\n",
       "      <td>196.433594</td>\n",
       "      <td>23.418732</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>decoders.2</td>\n",
       "      <td>ConvTranspose2d</td>\n",
       "      <td>(512, 512, 2, 2)</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>1049088</td>\n",
       "      <td>35.004063</td>\n",
       "      <td>25.395571</td>\n",
       "      <td>89.083595</td>\n",
       "      <td>8.937863</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>decoders.3.net.0</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(512, 1024, 3, 3)</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>4718592</td>\n",
       "      <td>195.009918</td>\n",
       "      <td>114.482597</td>\n",
       "      <td>330.603760</td>\n",
       "      <td>47.722992</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>decoders.3.net.3</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(512, 512, 3, 3)</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>2359296</td>\n",
       "      <td>121.828407</td>\n",
       "      <td>70.042984</td>\n",
       "      <td>208.503860</td>\n",
       "      <td>24.941704</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>decoders.4</td>\n",
       "      <td>ConvTranspose2d</td>\n",
       "      <td>(512, 256, 2, 2)</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>524544</td>\n",
       "      <td>22.916687</td>\n",
       "      <td>16.601276</td>\n",
       "      <td>49.586506</td>\n",
       "      <td>5.298937</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>decoders.5.net.0</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(256, 512, 3, 3)</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>1179648</td>\n",
       "      <td>111.650238</td>\n",
       "      <td>72.193024</td>\n",
       "      <td>171.599548</td>\n",
       "      <td>22.337379</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>decoders.5.net.3</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(256, 256, 3, 3)</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>589824</td>\n",
       "      <td>61.227055</td>\n",
       "      <td>35.621437</td>\n",
       "      <td>105.757797</td>\n",
       "      <td>14.611322</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>decoders.6</td>\n",
       "      <td>ConvTranspose2d</td>\n",
       "      <td>(256, 128, 2, 2)</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>131200</td>\n",
       "      <td>15.037172</td>\n",
       "      <td>11.295192</td>\n",
       "      <td>35.292168</td>\n",
       "      <td>3.810961</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>decoders.7.net.0</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(128, 256, 3, 3)</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>294912</td>\n",
       "      <td>55.959229</td>\n",
       "      <td>32.241714</td>\n",
       "      <td>88.714561</td>\n",
       "      <td>12.207071</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>decoders.7.net.3</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(128, 128, 3, 3)</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>147456</td>\n",
       "      <td>29.852371</td>\n",
       "      <td>18.079388</td>\n",
       "      <td>49.969971</td>\n",
       "      <td>6.246173</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>decoders.8</td>\n",
       "      <td>ConvTranspose2d</td>\n",
       "      <td>(128, 64, 2, 2)</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>32832</td>\n",
       "      <td>9.639632</td>\n",
       "      <td>7.661550</td>\n",
       "      <td>14.853378</td>\n",
       "      <td>1.382385</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>decoders.9.net.0</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(64, 128, 3, 3)</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>73728</td>\n",
       "      <td>24.609871</td>\n",
       "      <td>19.465464</td>\n",
       "      <td>34.851120</td>\n",
       "      <td>3.115485</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>decoders.9.net.3</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(64, 64, 3, 3)</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>36864</td>\n",
       "      <td>14.632851</td>\n",
       "      <td>12.428347</td>\n",
       "      <td>19.524097</td>\n",
       "      <td>1.466557</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>final_conv</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(4, 64, 1, 1)</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>260</td>\n",
       "      <td>14.455564</td>\n",
       "      <td>14.050569</td>\n",
       "      <td>14.798100</td>\n",
       "      <td>0.348094</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Layer             Type               Shape  In Ch  Out Ch  \\\n",
       "0   encoders.0.net.0           Conv2d       (64, 1, 3, 3)      1      64   \n",
       "1   encoders.0.net.3           Conv2d      (64, 64, 3, 3)     64      64   \n",
       "2   encoders.1.net.0           Conv2d     (128, 64, 3, 3)     64     128   \n",
       "3   encoders.1.net.3           Conv2d    (128, 128, 3, 3)    128     128   \n",
       "4   encoders.2.net.0           Conv2d    (256, 128, 3, 3)    128     256   \n",
       "5   encoders.2.net.3           Conv2d    (256, 256, 3, 3)    256     256   \n",
       "6   encoders.3.net.0           Conv2d    (512, 256, 3, 3)    256     512   \n",
       "7   encoders.3.net.3           Conv2d    (512, 512, 3, 3)    512     512   \n",
       "8   encoders.4.net.0           Conv2d    (512, 512, 3, 3)    512     512   \n",
       "9   encoders.4.net.3           Conv2d    (512, 512, 3, 3)    512     512   \n",
       "10  bottleneck.net.0           Conv2d   (1024, 512, 3, 3)    512    1024   \n",
       "11  bottleneck.net.3           Conv2d  (1024, 1024, 3, 3)   1024    1024   \n",
       "12        decoders.0  ConvTranspose2d   (1024, 512, 2, 2)   1024     512   \n",
       "13  decoders.1.net.0           Conv2d   (512, 1024, 3, 3)   1024     512   \n",
       "14  decoders.1.net.3           Conv2d    (512, 512, 3, 3)    512     512   \n",
       "15        decoders.2  ConvTranspose2d    (512, 512, 2, 2)    512     512   \n",
       "16  decoders.3.net.0           Conv2d   (512, 1024, 3, 3)   1024     512   \n",
       "17  decoders.3.net.3           Conv2d    (512, 512, 3, 3)    512     512   \n",
       "18        decoders.4  ConvTranspose2d    (512, 256, 2, 2)    512     256   \n",
       "19  decoders.5.net.0           Conv2d    (256, 512, 3, 3)    512     256   \n",
       "20  decoders.5.net.3           Conv2d    (256, 256, 3, 3)    256     256   \n",
       "21        decoders.6  ConvTranspose2d    (256, 128, 2, 2)    256     128   \n",
       "22  decoders.7.net.0           Conv2d    (128, 256, 3, 3)    256     128   \n",
       "23  decoders.7.net.3           Conv2d    (128, 128, 3, 3)    128     128   \n",
       "24        decoders.8  ConvTranspose2d     (128, 64, 2, 2)    128      64   \n",
       "25  decoders.9.net.0           Conv2d     (64, 128, 3, 3)    128      64   \n",
       "26  decoders.9.net.3           Conv2d      (64, 64, 3, 3)     64      64   \n",
       "27        final_conv           Conv2d       (4, 64, 1, 1)     64       4   \n",
       "\n",
       "    Num Params     Mean L1      Min L1      Max L1     L1 Std Block Ratio  \\\n",
       "0          576    1.551331    0.941511    2.025421   0.252934        None   \n",
       "1        36864   20.288008   14.836420   26.348740   2.820510        None   \n",
       "2        73728   20.560497   13.653543   29.073994   4.398217        None   \n",
       "3       147456   32.678024   21.367718   49.799278   6.812839        None   \n",
       "4       294912   34.095963   20.778049   52.540321   6.267731        None   \n",
       "5       589824   64.204262   35.262543   92.003357  13.836428        None   \n",
       "6      1179648   68.175964   34.533218   98.012207  13.933917        None   \n",
       "7      2359296  124.219528   53.179050  185.167419  25.643438        None   \n",
       "8      2359296  157.922775  100.266998  218.526779  16.962074        None   \n",
       "9      2359296  157.622177  109.752975  203.895996  16.077797        None   \n",
       "10     4718592  144.267090  101.880554  178.879700  14.665365        None   \n",
       "11     9437184  223.883591  106.554153  386.406921  57.562244        None   \n",
       "12     2097664   44.556839   25.305153  105.051765  13.880632        None   \n",
       "13     4718592  238.616776  123.579475  373.426453  47.908344        None   \n",
       "14     2359296  124.202682   67.089867  196.433594  23.418732        None   \n",
       "15     1049088   35.004063   25.395571   89.083595   8.937863        None   \n",
       "16     4718592  195.009918  114.482597  330.603760  47.722992        None   \n",
       "17     2359296  121.828407   70.042984  208.503860  24.941704        None   \n",
       "18      524544   22.916687   16.601276   49.586506   5.298937        None   \n",
       "19     1179648  111.650238   72.193024  171.599548  22.337379        None   \n",
       "20      589824   61.227055   35.621437  105.757797  14.611322        None   \n",
       "21      131200   15.037172   11.295192   35.292168   3.810961        None   \n",
       "22      294912   55.959229   32.241714   88.714561  12.207071        None   \n",
       "23      147456   29.852371   18.079388   49.969971   6.246173        None   \n",
       "24       32832    9.639632    7.661550   14.853378   1.382385        None   \n",
       "25       73728   24.609871   19.465464   34.851120   3.115485        None   \n",
       "26       36864   14.632851   12.428347   19.524097   1.466557        None   \n",
       "27         260   14.455564   14.050569   14.798100   0.348094        None   \n",
       "\n",
       "   Post-Prune Ratio  \n",
       "0              None  \n",
       "1              None  \n",
       "2              None  \n",
       "3              None  \n",
       "4              None  \n",
       "5              None  \n",
       "6              None  \n",
       "7              None  \n",
       "8              None  \n",
       "9              None  \n",
       "10             None  \n",
       "11             None  \n",
       "12             None  \n",
       "13             None  \n",
       "14             None  \n",
       "15             None  \n",
       "16             None  \n",
       "17             None  \n",
       "18             None  \n",
       "19             None  \n",
       "20             None  \n",
       "21             None  \n",
       "22             None  \n",
       "23             None  \n",
       "24             None  \n",
       "25             None  \n",
       "26             None  \n",
       "27             None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2Ô∏è‚É£ Compute per-filter L1 norms\n",
    "norms = compute_l1_norms(model)\n",
    "\n",
    "# 3Ô∏è‚É£ Compute L1 statistics from norms\n",
    "l1_stats = compute_l1_stats(norms)\n",
    "\n",
    "# 4Ô∏è‚É£ (Optional) define block ratios for later reference\n",
    "#block_ratios = {\"encoders.0\": 0.2, \"encoders.1\": 0.3, \"bottleneck\": 0.4}\n",
    "\n",
    "# 5Ô∏è‚É£ Build DataFrame with stats\n",
    "df = model_to_dataframe_with_l1(\n",
    "    model,\n",
    "    l1_stats=l1_stats,\n",
    "    remove_nan_layers=True\n",
    ")\n",
    "\n",
    "# 6Ô∏è‚É£ Display full DataFrame\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "976be945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Generating pruning masks...\n",
      "\n",
      "Block encoders.0      | ratio=0.00 ‚Üí keeping all 64 filters.\n",
      "Block encoders.0      | ratio=0.00 ‚Üí keeping all 64 filters.\n",
      "Block encoders.1      | ratio=0.00 ‚Üí keeping all 128 filters.\n",
      "Block encoders.1      | ratio=0.00 ‚Üí keeping all 128 filters.\n",
      "Block encoders.2      | ratio=0.00 ‚Üí keeping all 256 filters.\n",
      "Block encoders.2      | ratio=0.00 ‚Üí keeping all 256 filters.\n",
      "Block encoders.3      | ratio=0.00 ‚Üí keeping all 512 filters.\n",
      "Block encoders.3      | ratio=0.00 ‚Üí keeping all 512 filters.\n",
      "Block encoders.4      | ratio=0.00 ‚Üí keeping all 512 filters.\n",
      "Block encoders.4      | ratio=0.00 ‚Üí keeping all 512 filters.\n",
      "Block bottleneck      | ratio=0.00 ‚Üí keeping all 1024 filters.\n",
      "Block bottleneck      | ratio=0.00 ‚Üí keeping all 1024 filters.\n",
      "Block decoders.1      | ratio=0.00 ‚Üí keeping all 512 filters.\n",
      "Block decoders.1      | ratio=0.00 ‚Üí keeping all 512 filters.\n",
      "Block decoders.3      | ratio=0.00 ‚Üí keeping all 512 filters.\n",
      "Block decoders.3      | ratio=0.00 ‚Üí keeping all 512 filters.\n",
      "Block decoders.5      | ratio=0.00 ‚Üí keeping all 256 filters.\n",
      "Block decoders.5      | ratio=0.00 ‚Üí keeping all 256 filters.\n",
      "Block decoders.7      | Layer decoders.7.net.0          | ratio=0.10 | thresh=39.2737 | kept 115/128\n",
      "Block decoders.7      | Layer decoders.7.net.3          | ratio=0.10 | thresh=19.9203 | kept 115/128\n",
      "Block decoders.9      | Layer decoders.9.net.0          | ratio=0.20 | thresh=21.5976 | kept 51/64\n",
      "Block decoders.9      | Layer decoders.9.net.3          | ratio=0.20 | thresh=13.4575 | kept 51/64\n"
     ]
    }
   ],
   "source": [
    "block_ratios = {\n",
    "    # --- Encoder DoubleConvs ---\n",
    "    \"encoders.0\": 0.0,\n",
    "    \"encoders.1\": 0.0,\n",
    "    \"encoders.2\": 0.0,\n",
    "    \"encoders.3\": 0.0,\n",
    "    \"encoders.4\": 0.0,\n",
    "\n",
    "    # --- Bottleneck ---\n",
    "    \"bottleneck\": 0.0,\n",
    "\n",
    "    # --- Decoder DoubleConvs only (skip ConvTranspose2d ones) ---\n",
    "    \"decoders.1\": 0.0,\n",
    "    \"decoders.3\": 0.0,\n",
    "    \"decoders.5\": 0.0,\n",
    "    \"decoders.7\": 0.1,\n",
    "    \"decoders.9\": 0.2,\n",
    "}\n",
    "\n",
    "\n",
    "# Then get the pruning masks\n",
    "masks = get_pruning_masks_blockwise(\n",
    "    model=model,\n",
    "    norms=norms,\n",
    "    block_ratios=block_ratios,\n",
    "    default_ratio=0.25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8938282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Rebuilding pruned UNet architecture...\n",
      "‚úÖ Built pruned UNet | enc: [64, 128, 256, 512, 512], dec: [512, 512, 256, 115, 51], bottleneck: 1024\n",
      "‚úÇÔ∏è Pruned copy ‚Üí encoders.0.net.0.weight: (64, 1, 3, 3)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.0.net.1.weight: (64,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.0.net.1.bias: (64,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.0.net.1.running_mean: (64,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.0.net.1.running_var: (64,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.0.net.1.num_batches_tracked: ()\n",
      "‚úÇÔ∏è Pruned copy ‚Üí encoders.0.net.3.weight: (64, 64, 3, 3)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.0.net.4.weight: (64,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.0.net.4.bias: (64,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.0.net.4.running_mean: (64,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.0.net.4.running_var: (64,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.0.net.4.num_batches_tracked: ()\n",
      "‚úÇÔ∏è Pruned copy ‚Üí encoders.1.net.0.weight: (128, 64, 3, 3)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.1.net.1.weight: (128,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.1.net.1.bias: (128,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.1.net.1.running_mean: (128,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.1.net.1.running_var: (128,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.1.net.1.num_batches_tracked: ()\n",
      "‚úÇÔ∏è Pruned copy ‚Üí encoders.1.net.3.weight: (128, 128, 3, 3)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.1.net.4.weight: (128,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.1.net.4.bias: (128,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.1.net.4.running_mean: (128,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.1.net.4.running_var: (128,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.1.net.4.num_batches_tracked: ()\n",
      "‚úÇÔ∏è Pruned copy ‚Üí encoders.2.net.0.weight: (256, 128, 3, 3)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.2.net.1.weight: (256,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.2.net.1.bias: (256,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.2.net.1.running_mean: (256,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.2.net.1.running_var: (256,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.2.net.1.num_batches_tracked: ()\n",
      "‚úÇÔ∏è Pruned copy ‚Üí encoders.2.net.3.weight: (256, 256, 3, 3)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.2.net.4.weight: (256,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.2.net.4.bias: (256,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.2.net.4.running_mean: (256,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.2.net.4.running_var: (256,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.2.net.4.num_batches_tracked: ()\n",
      "‚úÇÔ∏è Pruned copy ‚Üí encoders.3.net.0.weight: (512, 256, 3, 3)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.3.net.1.weight: (512,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.3.net.1.bias: (512,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.3.net.1.running_mean: (512,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.3.net.1.running_var: (512,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.3.net.1.num_batches_tracked: ()\n",
      "‚úÇÔ∏è Pruned copy ‚Üí encoders.3.net.3.weight: (512, 512, 3, 3)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.3.net.4.weight: (512,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.3.net.4.bias: (512,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.3.net.4.running_mean: (512,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.3.net.4.running_var: (512,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.3.net.4.num_batches_tracked: ()\n",
      "‚úÇÔ∏è Pruned copy ‚Üí encoders.4.net.0.weight: (512, 512, 3, 3)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.4.net.1.weight: (512,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.4.net.1.bias: (512,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.4.net.1.running_mean: (512,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.4.net.1.running_var: (512,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.4.net.1.num_batches_tracked: ()\n",
      "‚úÇÔ∏è Pruned copy ‚Üí encoders.4.net.3.weight: (512, 512, 3, 3)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.4.net.4.weight: (512,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.4.net.4.bias: (512,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.4.net.4.running_mean: (512,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.4.net.4.running_var: (512,)\n",
      "üì• Copied non-pruned layer ‚Üí encoders.4.net.4.num_batches_tracked: ()\n",
      "‚úÇÔ∏è Pruned copy ‚Üí bottleneck.net.0.weight: (1024, 512, 3, 3)\n",
      "üì• Copied non-pruned layer ‚Üí bottleneck.net.1.weight: (1024,)\n",
      "üì• Copied non-pruned layer ‚Üí bottleneck.net.1.bias: (1024,)\n",
      "üì• Copied non-pruned layer ‚Üí bottleneck.net.1.running_mean: (1024,)\n",
      "üì• Copied non-pruned layer ‚Üí bottleneck.net.1.running_var: (1024,)\n",
      "üì• Copied non-pruned layer ‚Üí bottleneck.net.1.num_batches_tracked: ()\n",
      "‚úÇÔ∏è Pruned copy ‚Üí bottleneck.net.3.weight: (1024, 1024, 3, 3)\n",
      "üì• Copied non-pruned layer ‚Üí bottleneck.net.4.weight: (1024,)\n",
      "üì• Copied non-pruned layer ‚Üí bottleneck.net.4.bias: (1024,)\n",
      "üì• Copied non-pruned layer ‚Üí bottleneck.net.4.running_mean: (1024,)\n",
      "üì• Copied non-pruned layer ‚Üí bottleneck.net.4.running_var: (1024,)\n",
      "üì• Copied non-pruned layer ‚Üí bottleneck.net.4.num_batches_tracked: ()\n",
      "üì• Copied non-pruned layer ‚Üí decoders.0.weight: (1024, 512, 2, 2)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.0.bias: (512,)\n",
      "‚úÇÔ∏è Pruned copy ‚Üí decoders.1.net.0.weight: (512, 1024, 3, 3)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.1.net.1.weight: (512,)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.1.net.1.bias: (512,)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.1.net.1.running_mean: (512,)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.1.net.1.running_var: (512,)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.1.net.1.num_batches_tracked: ()\n",
      "‚úÇÔ∏è Pruned copy ‚Üí decoders.1.net.3.weight: (512, 512, 3, 3)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.1.net.4.weight: (512,)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.1.net.4.bias: (512,)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.1.net.4.running_mean: (512,)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.1.net.4.running_var: (512,)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.1.net.4.num_batches_tracked: ()\n",
      "üì• Copied non-pruned layer ‚Üí decoders.2.weight: (512, 512, 2, 2)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.2.bias: (512,)\n",
      "‚úÇÔ∏è Pruned copy ‚Üí decoders.3.net.0.weight: (512, 1024, 3, 3)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.3.net.1.weight: (512,)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.3.net.1.bias: (512,)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.3.net.1.running_mean: (512,)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.3.net.1.running_var: (512,)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.3.net.1.num_batches_tracked: ()\n",
      "‚úÇÔ∏è Pruned copy ‚Üí decoders.3.net.3.weight: (512, 512, 3, 3)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.3.net.4.weight: (512,)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.3.net.4.bias: (512,)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.3.net.4.running_mean: (512,)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.3.net.4.running_var: (512,)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.3.net.4.num_batches_tracked: ()\n",
      "üì• Copied non-pruned layer ‚Üí decoders.4.weight: (512, 256, 2, 2)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.4.bias: (256,)\n",
      "‚úÇÔ∏è Pruned copy ‚Üí decoders.5.net.0.weight: (256, 512, 3, 3)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.5.net.1.weight: (256,)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.5.net.1.bias: (256,)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.5.net.1.running_mean: (256,)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.5.net.1.running_var: (256,)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.5.net.1.num_batches_tracked: ()\n",
      "‚úÇÔ∏è Pruned copy ‚Üí decoders.5.net.3.weight: (256, 256, 3, 3)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.5.net.4.weight: (256,)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.5.net.4.bias: (256,)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.5.net.4.running_mean: (256,)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.5.net.4.running_var: (256,)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.5.net.4.num_batches_tracked: ()\n",
      "üîß Correcting shape for decoders.6.weight: torch.Size([256, 128, 2, 2]) ‚Üí torch.Size([256, 115, 2, 2])\n",
      "üì• Copied non-pruned layer ‚Üí decoders.6.weight: (256, 115, 2, 2)\n",
      "üîß Correcting shape for decoders.6.bias: torch.Size([128]) ‚Üí torch.Size([115])\n",
      "üì• Copied non-pruned layer ‚Üí decoders.6.bias: (115,)\n",
      "‚ö†Ô∏è Shape mismatch in decoders.7.net.0.weight, adjusting‚Ä¶\n",
      "‚úÇÔ∏è Pruned copy ‚Üí decoders.7.net.0.weight: (115, 243, 3, 3)\n",
      "üîß Correcting shape for decoders.7.net.1.weight: torch.Size([128]) ‚Üí torch.Size([115])\n",
      "üì• Copied non-pruned layer ‚Üí decoders.7.net.1.weight: (115,)\n",
      "üîß Correcting shape for decoders.7.net.1.bias: torch.Size([128]) ‚Üí torch.Size([115])\n",
      "üì• Copied non-pruned layer ‚Üí decoders.7.net.1.bias: (115,)\n",
      "üîß Correcting shape for decoders.7.net.1.running_mean: torch.Size([128]) ‚Üí torch.Size([115])\n",
      "üì• Copied non-pruned layer ‚Üí decoders.7.net.1.running_mean: (115,)\n",
      "üîß Correcting shape for decoders.7.net.1.running_var: torch.Size([128]) ‚Üí torch.Size([115])\n",
      "üì• Copied non-pruned layer ‚Üí decoders.7.net.1.running_var: (115,)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.7.net.1.num_batches_tracked: ()\n",
      "‚ö†Ô∏è Shape mismatch in decoders.7.net.3.weight, adjusting‚Ä¶\n",
      "‚úÇÔ∏è Pruned copy ‚Üí decoders.7.net.3.weight: (115, 115, 3, 3)\n",
      "üîß Correcting shape for decoders.7.net.4.weight: torch.Size([128]) ‚Üí torch.Size([115])\n",
      "üì• Copied non-pruned layer ‚Üí decoders.7.net.4.weight: (115,)\n",
      "üîß Correcting shape for decoders.7.net.4.bias: torch.Size([128]) ‚Üí torch.Size([115])\n",
      "üì• Copied non-pruned layer ‚Üí decoders.7.net.4.bias: (115,)\n",
      "üîß Correcting shape for decoders.7.net.4.running_mean: torch.Size([128]) ‚Üí torch.Size([115])\n",
      "üì• Copied non-pruned layer ‚Üí decoders.7.net.4.running_mean: (115,)\n",
      "üîß Correcting shape for decoders.7.net.4.running_var: torch.Size([128]) ‚Üí torch.Size([115])\n",
      "üì• Copied non-pruned layer ‚Üí decoders.7.net.4.running_var: (115,)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.7.net.4.num_batches_tracked: ()\n",
      "üîß Correcting shape for decoders.8.weight: torch.Size([128, 64, 2, 2]) ‚Üí torch.Size([115, 51, 2, 2])\n",
      "üì• Copied non-pruned layer ‚Üí decoders.8.weight: (115, 51, 2, 2)\n",
      "üîß Correcting shape for decoders.8.bias: torch.Size([64]) ‚Üí torch.Size([51])\n",
      "üì• Copied non-pruned layer ‚Üí decoders.8.bias: (51,)\n",
      "‚ö†Ô∏è Shape mismatch in decoders.9.net.0.weight, adjusting‚Ä¶\n",
      "‚úÇÔ∏è Pruned copy ‚Üí decoders.9.net.0.weight: (51, 115, 3, 3)\n",
      "üîß Correcting shape for decoders.9.net.1.weight: torch.Size([64]) ‚Üí torch.Size([51])\n",
      "üì• Copied non-pruned layer ‚Üí decoders.9.net.1.weight: (51,)\n",
      "üîß Correcting shape for decoders.9.net.1.bias: torch.Size([64]) ‚Üí torch.Size([51])\n",
      "üì• Copied non-pruned layer ‚Üí decoders.9.net.1.bias: (51,)\n",
      "üîß Correcting shape for decoders.9.net.1.running_mean: torch.Size([64]) ‚Üí torch.Size([51])\n",
      "üì• Copied non-pruned layer ‚Üí decoders.9.net.1.running_mean: (51,)\n",
      "üîß Correcting shape for decoders.9.net.1.running_var: torch.Size([64]) ‚Üí torch.Size([51])\n",
      "üì• Copied non-pruned layer ‚Üí decoders.9.net.1.running_var: (51,)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.9.net.1.num_batches_tracked: ()\n",
      "‚ö†Ô∏è Shape mismatch in decoders.9.net.3.weight, adjusting‚Ä¶\n",
      "‚úÇÔ∏è Pruned copy ‚Üí decoders.9.net.3.weight: (51, 51, 3, 3)\n",
      "üîß Correcting shape for decoders.9.net.4.weight: torch.Size([64]) ‚Üí torch.Size([51])\n",
      "üì• Copied non-pruned layer ‚Üí decoders.9.net.4.weight: (51,)\n",
      "üîß Correcting shape for decoders.9.net.4.bias: torch.Size([64]) ‚Üí torch.Size([51])\n",
      "üì• Copied non-pruned layer ‚Üí decoders.9.net.4.bias: (51,)\n",
      "üîß Correcting shape for decoders.9.net.4.running_mean: torch.Size([64]) ‚Üí torch.Size([51])\n",
      "üì• Copied non-pruned layer ‚Üí decoders.9.net.4.running_mean: (51,)\n",
      "üîß Correcting shape for decoders.9.net.4.running_var: torch.Size([64]) ‚Üí torch.Size([51])\n",
      "üì• Copied non-pruned layer ‚Üí decoders.9.net.4.running_var: (51,)\n",
      "üì• Copied non-pruned layer ‚Üí decoders.9.net.4.num_batches_tracked: ()\n",
      "‚ö†Ô∏è Shape mismatch in final_conv.weight, adjusting‚Ä¶\n",
      "‚úÇÔ∏è Pruned copy ‚Üí final_conv.weight: (4, 51, 1, 1)\n",
      "‚úÇÔ∏è Pruned copy ‚Üí final_conv.bias: (4,)\n",
      "\n",
      "‚úÖ Weight reconstruction completed.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved pruned model to /media/ttoxopeus/basic_UNet/results/UNet_ACDC/exp41/pruned/pruned_model.pth\n",
      "‚úÖ UNet successfully rebuilt.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "pruned_model = rebuild_pruned_unet(\n",
    "    model,\n",
    "    masks, \n",
    "    save_path=Path(\"/media/ttoxopeus/basic_UNet/results/UNet_ACDC/exp41/pruned/pruned_model.pth\"))\n",
    "\n",
    "post_ratios = compute_actual_prune_ratios(model, pruned_model)\n",
    "\n",
    "\n",
    "\n",
    "# def summarize_model(model):\n",
    "#     \"\"\"\n",
    "#     Prints a detailed summary useful for debugging structured pruning.\n",
    "#     Includes:\n",
    "#     - module name\n",
    "#     - type\n",
    "#     - weight/bias shapes\n",
    "#     - in/out channels\n",
    "#     - parameter count\n",
    "#     - prunable (Conv2d or ConvTranspose2d)\n",
    "#     \"\"\"\n",
    "\n",
    "#     print(\"\\nüìò DETAILED MODEL SUMMARY\\n\" + \"-\"*100)\n",
    "\n",
    "#     for name, module in model.named_modules():\n",
    "#         if name == \"\":\n",
    "#             continue\n",
    "\n",
    "#         indent = \"  \" * name.count(\".\")\n",
    "#         out = f\"{indent}- {name:<40} ({module.__class__.__name__})\"\n",
    "\n",
    "#         # ---- parameter shapes ----\n",
    "#         if hasattr(module, \"weight\") and module.weight is not None:\n",
    "#             out += f\"\\n{indent}    weight: {tuple(module.weight.shape)}\"\n",
    "\n",
    "#         if hasattr(module, \"bias\") and module.bias is not None:\n",
    "#             out += f\"\\n{indent}    bias:   {tuple(module.bias.shape)}\"\n",
    "\n",
    "#         # ---- in/out channels ----\n",
    "#         if isinstance(module, nn.Conv2d) or isinstance(module, nn.ConvTranspose2d):\n",
    "#             out += (f\"\\n{indent}    in_ch: {module.in_channels}, \"\n",
    "#                     f\"out_ch: {module.out_channels}\")\n",
    "\n",
    "#         # ---- number of parameters ----\n",
    "#         n_params = sum(p.numel() for p in module.parameters() if p is not None)\n",
    "#         out += f\"\\n{indent}    params: {n_params}\"\n",
    "\n",
    "#         # ---- prunable? ----\n",
    "#         prunable = isinstance(module, (nn.Conv2d, nn.ConvTranspose2d))\n",
    "#         out += f\"\\n{indent}    prunable: {prunable}\"\n",
    "\n",
    "#         print(out + \"\\n\")\n",
    "\n",
    "#     print(\"-\"*100)\n",
    "\n",
    "\n",
    "# summarize_model(model)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e717e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer</th>\n",
       "      <th>Type</th>\n",
       "      <th>Shape</th>\n",
       "      <th>In Ch</th>\n",
       "      <th>Out Ch</th>\n",
       "      <th>Num Params</th>\n",
       "      <th>Mean L1</th>\n",
       "      <th>Min L1</th>\n",
       "      <th>Max L1</th>\n",
       "      <th>L1 Std</th>\n",
       "      <th>Block Ratio</th>\n",
       "      <th>Post-Prune Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>encoders.0.net.0</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(64, 1, 3, 3)</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>576</td>\n",
       "      <td>1.551331</td>\n",
       "      <td>0.941511</td>\n",
       "      <td>2.025421</td>\n",
       "      <td>0.252934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>encoders.0.net.3</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(64, 64, 3, 3)</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>36864</td>\n",
       "      <td>20.288008</td>\n",
       "      <td>14.836420</td>\n",
       "      <td>26.348740</td>\n",
       "      <td>2.820510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>encoders.1.net.0</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(128, 64, 3, 3)</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>73728</td>\n",
       "      <td>20.560497</td>\n",
       "      <td>13.653543</td>\n",
       "      <td>29.073994</td>\n",
       "      <td>4.398217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>encoders.1.net.3</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(128, 128, 3, 3)</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>147456</td>\n",
       "      <td>32.678024</td>\n",
       "      <td>21.367718</td>\n",
       "      <td>49.799278</td>\n",
       "      <td>6.812839</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>encoders.2.net.0</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(256, 128, 3, 3)</td>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>294912</td>\n",
       "      <td>34.095963</td>\n",
       "      <td>20.778049</td>\n",
       "      <td>52.540321</td>\n",
       "      <td>6.267731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>encoders.2.net.3</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(256, 256, 3, 3)</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>589824</td>\n",
       "      <td>64.204262</td>\n",
       "      <td>35.262543</td>\n",
       "      <td>92.003357</td>\n",
       "      <td>13.836428</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>encoders.3.net.0</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(512, 256, 3, 3)</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>1179648</td>\n",
       "      <td>68.175964</td>\n",
       "      <td>34.533218</td>\n",
       "      <td>98.012207</td>\n",
       "      <td>13.933917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>encoders.3.net.3</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(512, 512, 3, 3)</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>2359296</td>\n",
       "      <td>124.219528</td>\n",
       "      <td>53.179050</td>\n",
       "      <td>185.167419</td>\n",
       "      <td>25.643438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>encoders.4.net.0</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(512, 512, 3, 3)</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>2359296</td>\n",
       "      <td>157.922775</td>\n",
       "      <td>100.266998</td>\n",
       "      <td>218.526779</td>\n",
       "      <td>16.962074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>encoders.4.net.3</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(512, 512, 3, 3)</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>2359296</td>\n",
       "      <td>157.622177</td>\n",
       "      <td>109.752975</td>\n",
       "      <td>203.895996</td>\n",
       "      <td>16.077797</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bottleneck.net.0</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(1024, 512, 3, 3)</td>\n",
       "      <td>512</td>\n",
       "      <td>1024</td>\n",
       "      <td>4718592</td>\n",
       "      <td>144.267090</td>\n",
       "      <td>101.880554</td>\n",
       "      <td>178.879700</td>\n",
       "      <td>14.665365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bottleneck.net.3</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(1024, 1024, 3, 3)</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>9437184</td>\n",
       "      <td>223.883591</td>\n",
       "      <td>106.554153</td>\n",
       "      <td>386.406921</td>\n",
       "      <td>57.562244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>decoders.0</td>\n",
       "      <td>ConvTranspose2d</td>\n",
       "      <td>(1024, 512, 2, 2)</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>2097664</td>\n",
       "      <td>44.556839</td>\n",
       "      <td>25.305153</td>\n",
       "      <td>105.051765</td>\n",
       "      <td>13.880632</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>decoders.1.net.0</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(512, 1024, 3, 3)</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>4718592</td>\n",
       "      <td>238.616776</td>\n",
       "      <td>123.579475</td>\n",
       "      <td>373.426453</td>\n",
       "      <td>47.908344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>decoders.1.net.3</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(512, 512, 3, 3)</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>2359296</td>\n",
       "      <td>124.202682</td>\n",
       "      <td>67.089867</td>\n",
       "      <td>196.433594</td>\n",
       "      <td>23.418732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>decoders.2</td>\n",
       "      <td>ConvTranspose2d</td>\n",
       "      <td>(512, 512, 2, 2)</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>1049088</td>\n",
       "      <td>35.004063</td>\n",
       "      <td>25.395571</td>\n",
       "      <td>89.083595</td>\n",
       "      <td>8.937863</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>decoders.3.net.0</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(512, 1024, 3, 3)</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>4718592</td>\n",
       "      <td>195.009918</td>\n",
       "      <td>114.482597</td>\n",
       "      <td>330.603760</td>\n",
       "      <td>47.722992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>decoders.3.net.3</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(512, 512, 3, 3)</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>2359296</td>\n",
       "      <td>121.828407</td>\n",
       "      <td>70.042984</td>\n",
       "      <td>208.503860</td>\n",
       "      <td>24.941704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>decoders.4</td>\n",
       "      <td>ConvTranspose2d</td>\n",
       "      <td>(512, 256, 2, 2)</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>524544</td>\n",
       "      <td>22.916687</td>\n",
       "      <td>16.601276</td>\n",
       "      <td>49.586506</td>\n",
       "      <td>5.298937</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>decoders.5.net.0</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(256, 512, 3, 3)</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>1179648</td>\n",
       "      <td>111.650238</td>\n",
       "      <td>72.193024</td>\n",
       "      <td>171.599548</td>\n",
       "      <td>22.337379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>decoders.5.net.3</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(256, 256, 3, 3)</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>589824</td>\n",
       "      <td>61.227055</td>\n",
       "      <td>35.621437</td>\n",
       "      <td>105.757797</td>\n",
       "      <td>14.611322</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>decoders.6</td>\n",
       "      <td>ConvTranspose2d</td>\n",
       "      <td>(256, 115, 2, 2)</td>\n",
       "      <td>256</td>\n",
       "      <td>115</td>\n",
       "      <td>117875</td>\n",
       "      <td>13.497406</td>\n",
       "      <td>10.253593</td>\n",
       "      <td>29.982958</td>\n",
       "      <td>3.390768</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>decoders.7.net.0</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(115, 243, 3, 3)</td>\n",
       "      <td>243</td>\n",
       "      <td>115</td>\n",
       "      <td>251505</td>\n",
       "      <td>55.273052</td>\n",
       "      <td>37.375183</td>\n",
       "      <td>84.198578</td>\n",
       "      <td>10.075349</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>decoders.7.net.3</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(115, 115, 3, 3)</td>\n",
       "      <td>115</td>\n",
       "      <td>115</td>\n",
       "      <td>119025</td>\n",
       "      <td>27.677149</td>\n",
       "      <td>17.706470</td>\n",
       "      <td>45.864384</td>\n",
       "      <td>4.753269</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>decoders.8</td>\n",
       "      <td>ConvTranspose2d</td>\n",
       "      <td>(115, 51, 2, 2)</td>\n",
       "      <td>115</td>\n",
       "      <td>51</td>\n",
       "      <td>23511</td>\n",
       "      <td>7.657495</td>\n",
       "      <td>6.095276</td>\n",
       "      <td>11.327482</td>\n",
       "      <td>1.055470</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>decoders.9.net.0</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(51, 115, 3, 3)</td>\n",
       "      <td>115</td>\n",
       "      <td>51</td>\n",
       "      <td>52785</td>\n",
       "      <td>22.885338</td>\n",
       "      <td>19.286627</td>\n",
       "      <td>32.873177</td>\n",
       "      <td>2.697108</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>decoders.9.net.3</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(51, 51, 3, 3)</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>23409</td>\n",
       "      <td>12.082713</td>\n",
       "      <td>10.559504</td>\n",
       "      <td>15.107922</td>\n",
       "      <td>1.140066</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>final_conv</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>(4, 51, 1, 1)</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>208</td>\n",
       "      <td>11.505784</td>\n",
       "      <td>11.094662</td>\n",
       "      <td>11.815850</td>\n",
       "      <td>0.301255</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Layer             Type               Shape  In Ch  Out Ch  \\\n",
       "0   encoders.0.net.0           Conv2d       (64, 1, 3, 3)      1      64   \n",
       "1   encoders.0.net.3           Conv2d      (64, 64, 3, 3)     64      64   \n",
       "2   encoders.1.net.0           Conv2d     (128, 64, 3, 3)     64     128   \n",
       "3   encoders.1.net.3           Conv2d    (128, 128, 3, 3)    128     128   \n",
       "4   encoders.2.net.0           Conv2d    (256, 128, 3, 3)    128     256   \n",
       "5   encoders.2.net.3           Conv2d    (256, 256, 3, 3)    256     256   \n",
       "6   encoders.3.net.0           Conv2d    (512, 256, 3, 3)    256     512   \n",
       "7   encoders.3.net.3           Conv2d    (512, 512, 3, 3)    512     512   \n",
       "8   encoders.4.net.0           Conv2d    (512, 512, 3, 3)    512     512   \n",
       "9   encoders.4.net.3           Conv2d    (512, 512, 3, 3)    512     512   \n",
       "10  bottleneck.net.0           Conv2d   (1024, 512, 3, 3)    512    1024   \n",
       "11  bottleneck.net.3           Conv2d  (1024, 1024, 3, 3)   1024    1024   \n",
       "12        decoders.0  ConvTranspose2d   (1024, 512, 2, 2)   1024     512   \n",
       "13  decoders.1.net.0           Conv2d   (512, 1024, 3, 3)   1024     512   \n",
       "14  decoders.1.net.3           Conv2d    (512, 512, 3, 3)    512     512   \n",
       "15        decoders.2  ConvTranspose2d    (512, 512, 2, 2)    512     512   \n",
       "16  decoders.3.net.0           Conv2d   (512, 1024, 3, 3)   1024     512   \n",
       "17  decoders.3.net.3           Conv2d    (512, 512, 3, 3)    512     512   \n",
       "18        decoders.4  ConvTranspose2d    (512, 256, 2, 2)    512     256   \n",
       "19  decoders.5.net.0           Conv2d    (256, 512, 3, 3)    512     256   \n",
       "20  decoders.5.net.3           Conv2d    (256, 256, 3, 3)    256     256   \n",
       "21        decoders.6  ConvTranspose2d    (256, 115, 2, 2)    256     115   \n",
       "22  decoders.7.net.0           Conv2d    (115, 243, 3, 3)    243     115   \n",
       "23  decoders.7.net.3           Conv2d    (115, 115, 3, 3)    115     115   \n",
       "24        decoders.8  ConvTranspose2d     (115, 51, 2, 2)    115      51   \n",
       "25  decoders.9.net.0           Conv2d     (51, 115, 3, 3)    115      51   \n",
       "26  decoders.9.net.3           Conv2d      (51, 51, 3, 3)     51      51   \n",
       "27        final_conv           Conv2d       (4, 51, 1, 1)     51       4   \n",
       "\n",
       "    Num Params     Mean L1      Min L1      Max L1     L1 Std Block Ratio  \\\n",
       "0          576    1.551331    0.941511    2.025421   0.252934         0.0   \n",
       "1        36864   20.288008   14.836420   26.348740   2.820510         0.0   \n",
       "2        73728   20.560497   13.653543   29.073994   4.398217         0.0   \n",
       "3       147456   32.678024   21.367718   49.799278   6.812839         0.0   \n",
       "4       294912   34.095963   20.778049   52.540321   6.267731         0.0   \n",
       "5       589824   64.204262   35.262543   92.003357  13.836428         0.0   \n",
       "6      1179648   68.175964   34.533218   98.012207  13.933917         0.0   \n",
       "7      2359296  124.219528   53.179050  185.167419  25.643438         0.0   \n",
       "8      2359296  157.922775  100.266998  218.526779  16.962074         0.0   \n",
       "9      2359296  157.622177  109.752975  203.895996  16.077797         0.0   \n",
       "10     4718592  144.267090  101.880554  178.879700  14.665365         0.0   \n",
       "11     9437184  223.883591  106.554153  386.406921  57.562244         0.0   \n",
       "12     2097664   44.556839   25.305153  105.051765  13.880632        None   \n",
       "13     4718592  238.616776  123.579475  373.426453  47.908344         0.0   \n",
       "14     2359296  124.202682   67.089867  196.433594  23.418732         0.0   \n",
       "15     1049088   35.004063   25.395571   89.083595   8.937863        None   \n",
       "16     4718592  195.009918  114.482597  330.603760  47.722992         0.0   \n",
       "17     2359296  121.828407   70.042984  208.503860  24.941704         0.0   \n",
       "18      524544   22.916687   16.601276   49.586506   5.298937        None   \n",
       "19     1179648  111.650238   72.193024  171.599548  22.337379         0.0   \n",
       "20      589824   61.227055   35.621437  105.757797  14.611322         0.0   \n",
       "21      117875   13.497406   10.253593   29.982958   3.390768        None   \n",
       "22      251505   55.273052   37.375183   84.198578  10.075349         0.1   \n",
       "23      119025   27.677149   17.706470   45.864384   4.753269         0.1   \n",
       "24       23511    7.657495    6.095276   11.327482   1.055470        None   \n",
       "25       52785   22.885338   19.286627   32.873177   2.697108         0.2   \n",
       "26       23409   12.082713   10.559504   15.107922   1.140066         0.2   \n",
       "27         208   11.505784   11.094662   11.815850   0.301255        None   \n",
       "\n",
       "   Post-Prune Ratio  \n",
       "0               0.0  \n",
       "1               0.0  \n",
       "2               0.0  \n",
       "3               0.0  \n",
       "4               0.0  \n",
       "5               0.0  \n",
       "6               0.0  \n",
       "7               0.0  \n",
       "8               0.0  \n",
       "9               0.0  \n",
       "10              0.0  \n",
       "11              0.0  \n",
       "12             None  \n",
       "13              0.0  \n",
       "14              0.0  \n",
       "15             None  \n",
       "16              0.0  \n",
       "17              0.0  \n",
       "18             None  \n",
       "19              0.0  \n",
       "20              0.0  \n",
       "21             None  \n",
       "22           0.1016  \n",
       "23           0.1016  \n",
       "24             None  \n",
       "25           0.2031  \n",
       "26           0.2031  \n",
       "27              0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2Ô∏è‚É£ Compute per-filter L1 norms\n",
    "pruned_norms = compute_l1_norms(pruned_model)\n",
    "\n",
    "# 3Ô∏è‚É£ Compute L1 statistics from norms\n",
    "pruned_l1_stats = compute_l1_stats(pruned_norms)\n",
    "\n",
    "\n",
    "df_pruned = model_to_dataframe_with_l1(\n",
    "    pruned_model,\n",
    "    l1_stats=pruned_l1_stats,\n",
    "    remove_nan_layers=True, \n",
    "    block_ratios=block_ratios,\n",
    "    post_prune_ratios=post_ratios\n",
    ")\n",
    "\n",
    "display(df_pruned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "084386b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer</th>\n",
       "      <th>Type_base</th>\n",
       "      <th>Num Params_base</th>\n",
       "      <th>Num Params_pruned</th>\n",
       "      <th>Mean L1_base</th>\n",
       "      <th>Mean L1_pruned</th>\n",
       "      <th>Min L1_base</th>\n",
       "      <th>Min L1_pruned</th>\n",
       "      <th>Max L1_base</th>\n",
       "      <th>Max L1_pruned</th>\n",
       "      <th>L1 Std_base</th>\n",
       "      <th>L1 Std_pruned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bottleneck.net.0</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>4718592</td>\n",
       "      <td>4718592</td>\n",
       "      <td>144.267090</td>\n",
       "      <td>144.267090</td>\n",
       "      <td>101.880554</td>\n",
       "      <td>101.880554</td>\n",
       "      <td>178.879700</td>\n",
       "      <td>178.879700</td>\n",
       "      <td>14.665365</td>\n",
       "      <td>14.665365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bottleneck.net.3</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>9437184</td>\n",
       "      <td>9437184</td>\n",
       "      <td>223.883591</td>\n",
       "      <td>223.883591</td>\n",
       "      <td>106.554153</td>\n",
       "      <td>106.554153</td>\n",
       "      <td>386.406921</td>\n",
       "      <td>386.406921</td>\n",
       "      <td>57.562244</td>\n",
       "      <td>57.562244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>decoders.0</td>\n",
       "      <td>ConvTranspose2d</td>\n",
       "      <td>2097664</td>\n",
       "      <td>2097664</td>\n",
       "      <td>44.556839</td>\n",
       "      <td>44.556839</td>\n",
       "      <td>25.305153</td>\n",
       "      <td>25.305153</td>\n",
       "      <td>105.051765</td>\n",
       "      <td>105.051765</td>\n",
       "      <td>13.880632</td>\n",
       "      <td>13.880632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>decoders.1.net.0</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>4718592</td>\n",
       "      <td>4718592</td>\n",
       "      <td>238.616776</td>\n",
       "      <td>238.616776</td>\n",
       "      <td>123.579475</td>\n",
       "      <td>123.579475</td>\n",
       "      <td>373.426453</td>\n",
       "      <td>373.426453</td>\n",
       "      <td>47.908344</td>\n",
       "      <td>47.908344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>decoders.1.net.3</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>2359296</td>\n",
       "      <td>2359296</td>\n",
       "      <td>124.202682</td>\n",
       "      <td>124.202682</td>\n",
       "      <td>67.089867</td>\n",
       "      <td>67.089867</td>\n",
       "      <td>196.433594</td>\n",
       "      <td>196.433594</td>\n",
       "      <td>23.418732</td>\n",
       "      <td>23.418732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>decoders.2</td>\n",
       "      <td>ConvTranspose2d</td>\n",
       "      <td>1049088</td>\n",
       "      <td>1049088</td>\n",
       "      <td>35.004063</td>\n",
       "      <td>35.004063</td>\n",
       "      <td>25.395571</td>\n",
       "      <td>25.395571</td>\n",
       "      <td>89.083595</td>\n",
       "      <td>89.083595</td>\n",
       "      <td>8.937863</td>\n",
       "      <td>8.937863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>decoders.3.net.0</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>4718592</td>\n",
       "      <td>4718592</td>\n",
       "      <td>195.009918</td>\n",
       "      <td>195.009918</td>\n",
       "      <td>114.482597</td>\n",
       "      <td>114.482597</td>\n",
       "      <td>330.603760</td>\n",
       "      <td>330.603760</td>\n",
       "      <td>47.722992</td>\n",
       "      <td>47.722992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>decoders.3.net.3</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>2359296</td>\n",
       "      <td>2359296</td>\n",
       "      <td>121.828407</td>\n",
       "      <td>121.828407</td>\n",
       "      <td>70.042984</td>\n",
       "      <td>70.042984</td>\n",
       "      <td>208.503860</td>\n",
       "      <td>208.503860</td>\n",
       "      <td>24.941704</td>\n",
       "      <td>24.941704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>decoders.4</td>\n",
       "      <td>ConvTranspose2d</td>\n",
       "      <td>524544</td>\n",
       "      <td>524544</td>\n",
       "      <td>22.916687</td>\n",
       "      <td>22.916687</td>\n",
       "      <td>16.601276</td>\n",
       "      <td>16.601276</td>\n",
       "      <td>49.586506</td>\n",
       "      <td>49.586506</td>\n",
       "      <td>5.298937</td>\n",
       "      <td>5.298937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>decoders.5.net.0</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>1179648</td>\n",
       "      <td>1179648</td>\n",
       "      <td>111.650238</td>\n",
       "      <td>111.650238</td>\n",
       "      <td>72.193024</td>\n",
       "      <td>72.193024</td>\n",
       "      <td>171.599548</td>\n",
       "      <td>171.599548</td>\n",
       "      <td>22.337379</td>\n",
       "      <td>22.337379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>decoders.5.net.3</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>589824</td>\n",
       "      <td>589824</td>\n",
       "      <td>61.227055</td>\n",
       "      <td>61.227055</td>\n",
       "      <td>35.621437</td>\n",
       "      <td>35.621437</td>\n",
       "      <td>105.757797</td>\n",
       "      <td>105.757797</td>\n",
       "      <td>14.611322</td>\n",
       "      <td>14.611322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>decoders.6</td>\n",
       "      <td>ConvTranspose2d</td>\n",
       "      <td>131200</td>\n",
       "      <td>117875</td>\n",
       "      <td>15.037172</td>\n",
       "      <td>13.497406</td>\n",
       "      <td>11.295192</td>\n",
       "      <td>10.253593</td>\n",
       "      <td>35.292168</td>\n",
       "      <td>29.982958</td>\n",
       "      <td>3.810961</td>\n",
       "      <td>3.390768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>decoders.7.net.0</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>294912</td>\n",
       "      <td>251505</td>\n",
       "      <td>55.959229</td>\n",
       "      <td>55.273052</td>\n",
       "      <td>32.241714</td>\n",
       "      <td>37.375183</td>\n",
       "      <td>88.714561</td>\n",
       "      <td>84.198578</td>\n",
       "      <td>12.207071</td>\n",
       "      <td>10.075349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>decoders.7.net.3</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>147456</td>\n",
       "      <td>119025</td>\n",
       "      <td>29.852371</td>\n",
       "      <td>27.677149</td>\n",
       "      <td>18.079388</td>\n",
       "      <td>17.706470</td>\n",
       "      <td>49.969971</td>\n",
       "      <td>45.864384</td>\n",
       "      <td>6.246173</td>\n",
       "      <td>4.753269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>decoders.8</td>\n",
       "      <td>ConvTranspose2d</td>\n",
       "      <td>32832</td>\n",
       "      <td>23511</td>\n",
       "      <td>9.639632</td>\n",
       "      <td>7.657495</td>\n",
       "      <td>7.661550</td>\n",
       "      <td>6.095276</td>\n",
       "      <td>14.853378</td>\n",
       "      <td>11.327482</td>\n",
       "      <td>1.382385</td>\n",
       "      <td>1.055470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>decoders.9.net.0</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>73728</td>\n",
       "      <td>52785</td>\n",
       "      <td>24.609871</td>\n",
       "      <td>22.885338</td>\n",
       "      <td>19.465464</td>\n",
       "      <td>19.286627</td>\n",
       "      <td>34.851120</td>\n",
       "      <td>32.873177</td>\n",
       "      <td>3.115485</td>\n",
       "      <td>2.697108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>decoders.9.net.3</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>36864</td>\n",
       "      <td>23409</td>\n",
       "      <td>14.632851</td>\n",
       "      <td>12.082713</td>\n",
       "      <td>12.428347</td>\n",
       "      <td>10.559504</td>\n",
       "      <td>19.524097</td>\n",
       "      <td>15.107922</td>\n",
       "      <td>1.466557</td>\n",
       "      <td>1.140066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>encoders.0.net.0</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>1.551331</td>\n",
       "      <td>1.551331</td>\n",
       "      <td>0.941511</td>\n",
       "      <td>0.941511</td>\n",
       "      <td>2.025421</td>\n",
       "      <td>2.025421</td>\n",
       "      <td>0.252934</td>\n",
       "      <td>0.252934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>encoders.0.net.3</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>36864</td>\n",
       "      <td>36864</td>\n",
       "      <td>20.288008</td>\n",
       "      <td>20.288008</td>\n",
       "      <td>14.836420</td>\n",
       "      <td>14.836420</td>\n",
       "      <td>26.348740</td>\n",
       "      <td>26.348740</td>\n",
       "      <td>2.820510</td>\n",
       "      <td>2.820510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>encoders.1.net.0</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>73728</td>\n",
       "      <td>73728</td>\n",
       "      <td>20.560497</td>\n",
       "      <td>20.560497</td>\n",
       "      <td>13.653543</td>\n",
       "      <td>13.653543</td>\n",
       "      <td>29.073994</td>\n",
       "      <td>29.073994</td>\n",
       "      <td>4.398217</td>\n",
       "      <td>4.398217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>encoders.1.net.3</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>147456</td>\n",
       "      <td>147456</td>\n",
       "      <td>32.678024</td>\n",
       "      <td>32.678024</td>\n",
       "      <td>21.367718</td>\n",
       "      <td>21.367718</td>\n",
       "      <td>49.799278</td>\n",
       "      <td>49.799278</td>\n",
       "      <td>6.812839</td>\n",
       "      <td>6.812839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>encoders.2.net.0</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>294912</td>\n",
       "      <td>294912</td>\n",
       "      <td>34.095963</td>\n",
       "      <td>34.095963</td>\n",
       "      <td>20.778049</td>\n",
       "      <td>20.778049</td>\n",
       "      <td>52.540321</td>\n",
       "      <td>52.540321</td>\n",
       "      <td>6.267731</td>\n",
       "      <td>6.267731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>encoders.2.net.3</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>589824</td>\n",
       "      <td>589824</td>\n",
       "      <td>64.204262</td>\n",
       "      <td>64.204262</td>\n",
       "      <td>35.262543</td>\n",
       "      <td>35.262543</td>\n",
       "      <td>92.003357</td>\n",
       "      <td>92.003357</td>\n",
       "      <td>13.836428</td>\n",
       "      <td>13.836428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>encoders.3.net.0</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>1179648</td>\n",
       "      <td>1179648</td>\n",
       "      <td>68.175964</td>\n",
       "      <td>68.175964</td>\n",
       "      <td>34.533218</td>\n",
       "      <td>34.533218</td>\n",
       "      <td>98.012207</td>\n",
       "      <td>98.012207</td>\n",
       "      <td>13.933917</td>\n",
       "      <td>13.933917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>encoders.3.net.3</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>2359296</td>\n",
       "      <td>2359296</td>\n",
       "      <td>124.219528</td>\n",
       "      <td>124.219528</td>\n",
       "      <td>53.179050</td>\n",
       "      <td>53.179050</td>\n",
       "      <td>185.167419</td>\n",
       "      <td>185.167419</td>\n",
       "      <td>25.643438</td>\n",
       "      <td>25.643438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>encoders.4.net.0</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>2359296</td>\n",
       "      <td>2359296</td>\n",
       "      <td>157.922775</td>\n",
       "      <td>157.922775</td>\n",
       "      <td>100.266998</td>\n",
       "      <td>100.266998</td>\n",
       "      <td>218.526779</td>\n",
       "      <td>218.526779</td>\n",
       "      <td>16.962074</td>\n",
       "      <td>16.962074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>encoders.4.net.3</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>2359296</td>\n",
       "      <td>2359296</td>\n",
       "      <td>157.622177</td>\n",
       "      <td>157.622177</td>\n",
       "      <td>109.752975</td>\n",
       "      <td>109.752975</td>\n",
       "      <td>203.895996</td>\n",
       "      <td>203.895996</td>\n",
       "      <td>16.077797</td>\n",
       "      <td>16.077797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>final_conv</td>\n",
       "      <td>Conv2d</td>\n",
       "      <td>260</td>\n",
       "      <td>208</td>\n",
       "      <td>14.455564</td>\n",
       "      <td>11.505784</td>\n",
       "      <td>14.050569</td>\n",
       "      <td>11.094662</td>\n",
       "      <td>14.798100</td>\n",
       "      <td>11.815850</td>\n",
       "      <td>0.348094</td>\n",
       "      <td>0.301255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Layer        Type_base  Num Params_base  Num Params_pruned  \\\n",
       "0   bottleneck.net.0           Conv2d          4718592            4718592   \n",
       "1   bottleneck.net.3           Conv2d          9437184            9437184   \n",
       "2         decoders.0  ConvTranspose2d          2097664            2097664   \n",
       "3   decoders.1.net.0           Conv2d          4718592            4718592   \n",
       "4   decoders.1.net.3           Conv2d          2359296            2359296   \n",
       "5         decoders.2  ConvTranspose2d          1049088            1049088   \n",
       "6   decoders.3.net.0           Conv2d          4718592            4718592   \n",
       "7   decoders.3.net.3           Conv2d          2359296            2359296   \n",
       "8         decoders.4  ConvTranspose2d           524544             524544   \n",
       "9   decoders.5.net.0           Conv2d          1179648            1179648   \n",
       "10  decoders.5.net.3           Conv2d           589824             589824   \n",
       "11        decoders.6  ConvTranspose2d           131200             117875   \n",
       "12  decoders.7.net.0           Conv2d           294912             251505   \n",
       "13  decoders.7.net.3           Conv2d           147456             119025   \n",
       "14        decoders.8  ConvTranspose2d            32832              23511   \n",
       "15  decoders.9.net.0           Conv2d            73728              52785   \n",
       "16  decoders.9.net.3           Conv2d            36864              23409   \n",
       "17  encoders.0.net.0           Conv2d              576                576   \n",
       "18  encoders.0.net.3           Conv2d            36864              36864   \n",
       "19  encoders.1.net.0           Conv2d            73728              73728   \n",
       "20  encoders.1.net.3           Conv2d           147456             147456   \n",
       "21  encoders.2.net.0           Conv2d           294912             294912   \n",
       "22  encoders.2.net.3           Conv2d           589824             589824   \n",
       "23  encoders.3.net.0           Conv2d          1179648            1179648   \n",
       "24  encoders.3.net.3           Conv2d          2359296            2359296   \n",
       "25  encoders.4.net.0           Conv2d          2359296            2359296   \n",
       "26  encoders.4.net.3           Conv2d          2359296            2359296   \n",
       "27        final_conv           Conv2d              260                208   \n",
       "\n",
       "    Mean L1_base  Mean L1_pruned  Min L1_base  Min L1_pruned  Max L1_base  \\\n",
       "0     144.267090      144.267090   101.880554     101.880554   178.879700   \n",
       "1     223.883591      223.883591   106.554153     106.554153   386.406921   \n",
       "2      44.556839       44.556839    25.305153      25.305153   105.051765   \n",
       "3     238.616776      238.616776   123.579475     123.579475   373.426453   \n",
       "4     124.202682      124.202682    67.089867      67.089867   196.433594   \n",
       "5      35.004063       35.004063    25.395571      25.395571    89.083595   \n",
       "6     195.009918      195.009918   114.482597     114.482597   330.603760   \n",
       "7     121.828407      121.828407    70.042984      70.042984   208.503860   \n",
       "8      22.916687       22.916687    16.601276      16.601276    49.586506   \n",
       "9     111.650238      111.650238    72.193024      72.193024   171.599548   \n",
       "10     61.227055       61.227055    35.621437      35.621437   105.757797   \n",
       "11     15.037172       13.497406    11.295192      10.253593    35.292168   \n",
       "12     55.959229       55.273052    32.241714      37.375183    88.714561   \n",
       "13     29.852371       27.677149    18.079388      17.706470    49.969971   \n",
       "14      9.639632        7.657495     7.661550       6.095276    14.853378   \n",
       "15     24.609871       22.885338    19.465464      19.286627    34.851120   \n",
       "16     14.632851       12.082713    12.428347      10.559504    19.524097   \n",
       "17      1.551331        1.551331     0.941511       0.941511     2.025421   \n",
       "18     20.288008       20.288008    14.836420      14.836420    26.348740   \n",
       "19     20.560497       20.560497    13.653543      13.653543    29.073994   \n",
       "20     32.678024       32.678024    21.367718      21.367718    49.799278   \n",
       "21     34.095963       34.095963    20.778049      20.778049    52.540321   \n",
       "22     64.204262       64.204262    35.262543      35.262543    92.003357   \n",
       "23     68.175964       68.175964    34.533218      34.533218    98.012207   \n",
       "24    124.219528      124.219528    53.179050      53.179050   185.167419   \n",
       "25    157.922775      157.922775   100.266998     100.266998   218.526779   \n",
       "26    157.622177      157.622177   109.752975     109.752975   203.895996   \n",
       "27     14.455564       11.505784    14.050569      11.094662    14.798100   \n",
       "\n",
       "    Max L1_pruned  L1 Std_base  L1 Std_pruned  \n",
       "0      178.879700    14.665365      14.665365  \n",
       "1      386.406921    57.562244      57.562244  \n",
       "2      105.051765    13.880632      13.880632  \n",
       "3      373.426453    47.908344      47.908344  \n",
       "4      196.433594    23.418732      23.418732  \n",
       "5       89.083595     8.937863       8.937863  \n",
       "6      330.603760    47.722992      47.722992  \n",
       "7      208.503860    24.941704      24.941704  \n",
       "8       49.586506     5.298937       5.298937  \n",
       "9      171.599548    22.337379      22.337379  \n",
       "10     105.757797    14.611322      14.611322  \n",
       "11      29.982958     3.810961       3.390768  \n",
       "12      84.198578    12.207071      10.075349  \n",
       "13      45.864384     6.246173       4.753269  \n",
       "14      11.327482     1.382385       1.055470  \n",
       "15      32.873177     3.115485       2.697108  \n",
       "16      15.107922     1.466557       1.140066  \n",
       "17       2.025421     0.252934       0.252934  \n",
       "18      26.348740     2.820510       2.820510  \n",
       "19      29.073994     4.398217       4.398217  \n",
       "20      49.799278     6.812839       6.812839  \n",
       "21      52.540321     6.267731       6.267731  \n",
       "22      92.003357    13.836428      13.836428  \n",
       "23      98.012207    13.933917      13.933917  \n",
       "24     185.167419    25.643438      25.643438  \n",
       "25     218.526779    16.962074      16.962074  \n",
       "26     203.895996    16.077797      16.077797  \n",
       "27      11.815850     0.348094       0.301255  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def interleave_compare(df_base: pd.DataFrame, df_pruned: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merge two layer-summary dataframes on 'Layer' and interleave\n",
    "    baseline and pruned columns for easy comparison.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: merged dataframe with interleaved _base and _pruned columns\n",
    "    \"\"\"\n",
    "\n",
    "    # Merge on layer name\n",
    "    dfm = df_base.merge(df_pruned, on=\"Layer\", how=\"outer\", suffixes=(\"_base\", \"_pruned\"))\n",
    "\n",
    "    # Identify columns\n",
    "    base_cols   = [c for c in dfm.columns if c.endswith(\"_base\")]\n",
    "    pruned_cols = [c for c in dfm.columns if c.endswith(\"_pruned\")]\n",
    "\n",
    "    # Build interleaved order\n",
    "    interleaved = [\"Layer\"]\n",
    "\n",
    "    for bc in base_cols:\n",
    "        stem = bc[:-5]          # remove \"_base\"\n",
    "        pc = stem + \"_pruned\"   # corresponding pruned col\n",
    "        interleaved.append(bc)\n",
    "        if pc in dfm.columns:\n",
    "            interleaved.append(pc)\n",
    "\n",
    "    # Add any remaining columns\n",
    "    for c in dfm.columns:\n",
    "        if c not in interleaved:\n",
    "            interleaved.append(c)\n",
    "\n",
    "    return dfm[interleaved]\n",
    "\n",
    "\n",
    "df_compare = interleave_compare(df, df_pruned)\n",
    "\n",
    "\n",
    "# display(df_compare.iloc[:, :-4])\n",
    "\n",
    "display(pd.concat([\n",
    "    df_compare.iloc[:, :2],     # first 2 columns\n",
    "    df_compare.iloc[:, 9:-4]    # your selected range\n",
    "], axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85ca743a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úî SAME: encoders.0.net.0.weight\n",
      "‚úî SAME: encoders.0.net.1.weight\n",
      "‚úî SAME: encoders.0.net.1.bias\n",
      "‚úî SAME: encoders.0.net.3.weight\n",
      "‚úî SAME: encoders.0.net.4.weight\n",
      "‚úî SAME: encoders.0.net.4.bias\n",
      "‚úî SAME: encoders.1.net.0.weight\n",
      "‚úî SAME: encoders.1.net.1.weight\n",
      "‚úî SAME: encoders.1.net.1.bias\n",
      "‚úî SAME: encoders.1.net.3.weight\n",
      "‚úî SAME: encoders.1.net.4.weight\n",
      "‚úî SAME: encoders.1.net.4.bias\n",
      "‚úî SAME: encoders.2.net.0.weight\n",
      "‚úî SAME: encoders.2.net.1.weight\n",
      "‚úî SAME: encoders.2.net.1.bias\n",
      "‚úî SAME: encoders.2.net.3.weight\n",
      "‚úî SAME: encoders.2.net.4.weight\n",
      "‚úî SAME: encoders.2.net.4.bias\n",
      "‚úî SAME: encoders.3.net.0.weight\n",
      "‚úî SAME: encoders.3.net.1.weight\n",
      "‚úî SAME: encoders.3.net.1.bias\n",
      "‚úî SAME: encoders.3.net.3.weight\n",
      "‚úî SAME: encoders.3.net.4.weight\n",
      "‚úî SAME: encoders.3.net.4.bias\n",
      "‚úî SAME: encoders.4.net.0.weight\n",
      "‚úî SAME: encoders.4.net.1.weight\n",
      "‚úî SAME: encoders.4.net.1.bias\n",
      "‚úî SAME: encoders.4.net.3.weight\n",
      "‚úî SAME: encoders.4.net.4.weight\n",
      "‚úî SAME: encoders.4.net.4.bias\n",
      "‚úî SAME: bottleneck.net.0.weight\n",
      "‚úî SAME: bottleneck.net.1.weight\n",
      "‚úî SAME: bottleneck.net.1.bias\n",
      "‚úî SAME: bottleneck.net.3.weight\n",
      "‚úî SAME: bottleneck.net.4.weight\n",
      "‚úî SAME: bottleneck.net.4.bias\n",
      "‚úî SAME: decoders.0.weight\n",
      "‚úî SAME: decoders.0.bias\n",
      "‚úî SAME: decoders.1.net.0.weight\n",
      "‚úî SAME: decoders.1.net.1.weight\n",
      "‚úî SAME: decoders.1.net.1.bias\n",
      "‚úî SAME: decoders.1.net.3.weight\n",
      "‚úî SAME: decoders.1.net.4.weight\n",
      "‚úî SAME: decoders.1.net.4.bias\n",
      "‚úî SAME: decoders.2.weight\n",
      "‚úî SAME: decoders.2.bias\n",
      "‚úî SAME: decoders.3.net.0.weight\n",
      "‚úî SAME: decoders.3.net.1.weight\n",
      "‚úî SAME: decoders.3.net.1.bias\n",
      "‚úî SAME: decoders.3.net.3.weight\n",
      "‚úî SAME: decoders.3.net.4.weight\n",
      "‚úî SAME: decoders.3.net.4.bias\n",
      "‚úî SAME: decoders.4.weight\n",
      "‚úî SAME: decoders.4.bias\n",
      "‚úî SAME: decoders.5.net.0.weight\n",
      "‚úî SAME: decoders.5.net.1.weight\n",
      "‚úî SAME: decoders.5.net.1.bias\n",
      "‚úî SAME: decoders.5.net.3.weight\n",
      "‚úî SAME: decoders.5.net.4.weight\n",
      "‚úî SAME: decoders.5.net.4.bias\n",
      "‚ùå SHAPE DIFF: decoders.6.weight: torch.Size([256, 128, 2, 2]) vs torch.Size([256, 115, 2, 2])\n",
      "‚ùå SHAPE DIFF: decoders.6.bias: torch.Size([128]) vs torch.Size([115])\n",
      "‚ùå SHAPE DIFF: decoders.7.net.0.weight: torch.Size([128, 256, 3, 3]) vs torch.Size([115, 243, 3, 3])\n",
      "‚ùå SHAPE DIFF: decoders.7.net.1.weight: torch.Size([128]) vs torch.Size([115])\n",
      "‚ùå SHAPE DIFF: decoders.7.net.1.bias: torch.Size([128]) vs torch.Size([115])\n",
      "‚ùå SHAPE DIFF: decoders.7.net.3.weight: torch.Size([128, 128, 3, 3]) vs torch.Size([115, 115, 3, 3])\n",
      "‚ùå SHAPE DIFF: decoders.7.net.4.weight: torch.Size([128]) vs torch.Size([115])\n",
      "‚ùå SHAPE DIFF: decoders.7.net.4.bias: torch.Size([128]) vs torch.Size([115])\n",
      "‚ùå SHAPE DIFF: decoders.8.weight: torch.Size([128, 64, 2, 2]) vs torch.Size([115, 51, 2, 2])\n",
      "‚ùå SHAPE DIFF: decoders.8.bias: torch.Size([64]) vs torch.Size([51])\n",
      "‚ùå SHAPE DIFF: decoders.9.net.0.weight: torch.Size([64, 128, 3, 3]) vs torch.Size([51, 115, 3, 3])\n",
      "‚ùå SHAPE DIFF: decoders.9.net.1.weight: torch.Size([64]) vs torch.Size([51])\n",
      "‚ùå SHAPE DIFF: decoders.9.net.1.bias: torch.Size([64]) vs torch.Size([51])\n",
      "‚ùå SHAPE DIFF: decoders.9.net.3.weight: torch.Size([64, 64, 3, 3]) vs torch.Size([51, 51, 3, 3])\n",
      "‚ùå SHAPE DIFF: decoders.9.net.4.weight: torch.Size([64]) vs torch.Size([51])\n",
      "‚ùå SHAPE DIFF: decoders.9.net.4.bias: torch.Size([64]) vs torch.Size([51])\n",
      "‚ùå SHAPE DIFF: final_conv.weight: torch.Size([4, 64, 1, 1]) vs torch.Size([4, 51, 1, 1])\n",
      "‚úî SAME: final_conv.bias\n",
      "\n",
      "================ SUMMARY ================\n",
      "Total layers:       78\n",
      "‚úî Identical:        61\n",
      "‚ùå Weight diffs:     0\n",
      "‚ùå Shape diffs:      17\n",
      "=========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def compare_models(model, pruned_model, atol=1e-6, verbose=True):\n",
    "    \"\"\"\n",
    "    Compare two PyTorch models layer-by-layer.\n",
    "\n",
    "    Shows:\n",
    "    - shape differences\n",
    "    - weight differences (allclose)\n",
    "    - mean/std differences\n",
    "    - summary counts\n",
    "\n",
    "    Args:\n",
    "        model: baseline model\n",
    "        pruned_model: pruned or rebuilt model\n",
    "        atol: absolute tolerance for allclose\n",
    "        verbose: whether to print per-layer info\n",
    "\n",
    "    Returns:\n",
    "        dict with summary stats\n",
    "    \"\"\"\n",
    "\n",
    "    diffs = []\n",
    "    same = []\n",
    "    shape_diffs = []\n",
    "    stats = []\n",
    "\n",
    "    for (name1, p1), (name2, p2) in zip(model.named_parameters(), pruned_model.named_parameters()):\n",
    "\n",
    "        if name1 != name2:\n",
    "            raise ValueError(f\"Layer order/name mismatch: {name1} != {name2}\")\n",
    "\n",
    "        # Shape mismatch\n",
    "        if p1.shape != p2.shape:\n",
    "            shape_diffs.append((name1, p1.shape, p2.shape))\n",
    "            if verbose:\n",
    "                print(f\"‚ùå SHAPE DIFF: {name1}: {p1.shape} vs {p2.shape}\")\n",
    "            continue\n",
    "\n",
    "        # Weight difference\n",
    "        equal = torch.allclose(p1, p2, atol=atol)\n",
    "\n",
    "        if equal:\n",
    "            same.append(name1)\n",
    "            if verbose:\n",
    "                print(f\"‚úî SAME: {name1}\")\n",
    "        else:\n",
    "            diffs.append(name1)\n",
    "            if verbose:\n",
    "                print(f\"‚ùå DIFF: {name1}\")\n",
    "\n",
    "        # Mean/std comparison\n",
    "        stats.append({\n",
    "            \"Layer\": name1,\n",
    "            \"Mean_base\": p1.mean().item(),\n",
    "            \"Mean_pruned\": p2.mean().item(),\n",
    "            \"Std_base\": p1.std().item(),\n",
    "            \"Std_pruned\": p2.std().item(),\n",
    "        })\n",
    "\n",
    "    summary = {\n",
    "        \"num_layers\": len(same) + len(diffs) + len(shape_diffs),\n",
    "        \"same_layers\": len(same),\n",
    "        \"diff_layers\": len(diffs),\n",
    "        \"shape_diffs\": len(shape_diffs),\n",
    "        \"same_list\": same,\n",
    "        \"diff_list\": diffs,\n",
    "        \"shape_diff_list\": shape_diffs,\n",
    "        \"stats\": stats,\n",
    "    }\n",
    "\n",
    "    print(\"\\n================ SUMMARY ================\")\n",
    "    print(f\"Total layers:       {summary['num_layers']}\")\n",
    "    print(f\"‚úî Identical:        {summary['same_layers']}\")\n",
    "    print(f\"‚ùå Weight diffs:     {summary['diff_layers']}\")\n",
    "    print(f\"‚ùå Shape diffs:      {summary['shape_diffs']}\")\n",
    "    print(\"=========================================\\n\")\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "summary = compare_models(model, pruned_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc5f1d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úî SAME: encoders.0.net.0.weight\n",
      "‚úî SAME: encoders.0.net.1.weight\n",
      "‚úî SAME: encoders.0.net.1.bias\n",
      "‚úî SAME: encoders.0.net.3.weight\n",
      "‚úî SAME: encoders.0.net.4.weight\n",
      "‚úî SAME: encoders.0.net.4.bias\n",
      "‚úî SAME: encoders.1.net.0.weight\n",
      "‚úî SAME: encoders.1.net.1.weight\n",
      "‚úî SAME: encoders.1.net.1.bias\n",
      "‚úî SAME: encoders.1.net.3.weight\n",
      "‚úî SAME: encoders.1.net.4.weight\n",
      "‚úî SAME: encoders.1.net.4.bias\n",
      "‚úî SAME: encoders.2.net.0.weight\n",
      "‚úî SAME: encoders.2.net.1.weight\n",
      "‚úî SAME: encoders.2.net.1.bias\n",
      "‚úî SAME: encoders.2.net.3.weight\n",
      "‚úî SAME: encoders.2.net.4.weight\n",
      "‚úî SAME: encoders.2.net.4.bias\n",
      "‚úî SAME: encoders.3.net.0.weight\n",
      "‚úî SAME: encoders.3.net.1.weight\n",
      "‚úî SAME: encoders.3.net.1.bias\n",
      "‚úî SAME: encoders.3.net.3.weight\n",
      "‚úî SAME: encoders.3.net.4.weight\n",
      "‚úî SAME: encoders.3.net.4.bias\n",
      "‚úî SAME: encoders.4.net.0.weight\n",
      "‚úî SAME: encoders.4.net.1.weight\n",
      "‚úî SAME: encoders.4.net.1.bias\n",
      "‚úî SAME: encoders.4.net.3.weight\n",
      "‚úî SAME: encoders.4.net.4.weight\n",
      "‚úî SAME: encoders.4.net.4.bias\n",
      "‚úî SAME: bottleneck.net.0.weight\n",
      "‚úî SAME: bottleneck.net.1.weight\n",
      "‚úî SAME: bottleneck.net.1.bias\n",
      "‚úî SAME: bottleneck.net.3.weight\n",
      "‚úî SAME: bottleneck.net.4.weight\n",
      "‚úî SAME: bottleneck.net.4.bias\n",
      "‚úî SAME: decoders.0.weight\n",
      "‚úî SAME: decoders.0.bias\n",
      "‚úî SAME: decoders.1.net.0.weight\n",
      "‚úî SAME: decoders.1.net.1.weight\n",
      "‚úî SAME: decoders.1.net.1.bias\n",
      "‚úî SAME: decoders.1.net.3.weight\n",
      "‚úî SAME: decoders.1.net.4.weight\n",
      "‚úî SAME: decoders.1.net.4.bias\n",
      "‚úî SAME: decoders.2.weight\n",
      "‚úî SAME: decoders.2.bias\n",
      "‚úî SAME: decoders.3.net.0.weight\n",
      "‚úî SAME: decoders.3.net.1.weight\n",
      "‚úî SAME: decoders.3.net.1.bias\n",
      "‚úî SAME: decoders.3.net.3.weight\n",
      "‚úî SAME: decoders.3.net.4.weight\n",
      "‚úî SAME: decoders.3.net.4.bias\n",
      "‚úî SAME: decoders.4.weight\n",
      "‚úî SAME: decoders.4.bias\n",
      "‚úî SAME: decoders.5.net.0.weight\n",
      "‚úî SAME: decoders.5.net.1.weight\n",
      "‚úî SAME: decoders.5.net.1.bias\n",
      "‚úî SAME: decoders.5.net.3.weight\n",
      "‚úî SAME: decoders.5.net.4.weight\n",
      "‚úî SAME: decoders.5.net.4.bias\n",
      "‚ùå SHAPE DIFF (slice mismatch): decoders.6.weight\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [256] at index 0 does not match the shape of the indexed tensor [128] at index 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 135\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;66;03m# 3. No associated mask\u001b[39;00m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[43mcompare_models_pruned\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpruned_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 60\u001b[0m, in \u001b[0;36mcompare_models_pruned\u001b[0;34m(model, pruned_model, masks, atol, verbose)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# For BN: weight, bias, running_mean, running_var\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m p1\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 60\u001b[0m     slice1 \u001b[38;5;241m=\u001b[39m \u001b[43mp1\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     61\u001b[0m     slice2 \u001b[38;5;241m=\u001b[39m p2\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [256] at index 0 does not match the shape of the indexed tensor [128] at index 0"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def compare_models_pruned(model, pruned_model, masks, atol=1e-6, verbose=True):\n",
    "    \"\"\"\n",
    "    Compare two models, compatible with pruned models.\n",
    "\n",
    "    If shapes differ, compares only the overlapping pruned slices:\n",
    "        - For Conv2d: out_channels + in_channels sliced by masks\n",
    "        - For BN: only sliced output channels\n",
    "        - For ConvTranspose2d: input channels sliced\n",
    "\n",
    "    Args:\n",
    "        model: original UNet\n",
    "        pruned_model: pruned UNet\n",
    "        masks: dict of pruning masks per module (True=keep)\n",
    "        atol: tolerance for allclose\n",
    "        verbose: print layer-by-layer details\n",
    "    \"\"\"\n",
    "\n",
    "    same = []\n",
    "    diffs = []\n",
    "    shape_diffs = []\n",
    "\n",
    "    for (name1, p1), (name2, p2) in zip(model.named_parameters(), pruned_model.named_parameters()):\n",
    "\n",
    "        if name1 != name2:\n",
    "            raise ValueError(f\"Layer mismatch: {name1} != {name2}\")\n",
    "\n",
    "        module_name = name1.rsplit(\".\", 1)[0]\n",
    "\n",
    "        # Case 1: shapes identical ‚Üí direct comparison\n",
    "        if p1.shape == p2.shape:\n",
    "            equal = torch.allclose(p1, p2, atol=atol)\n",
    "            if equal:\n",
    "                same.append(name1)\n",
    "                if verbose: print(f\"‚úî SAME: {name1}\")\n",
    "            else:\n",
    "                diffs.append(name1)\n",
    "                if verbose: print(f\"‚ùå DIFF: {name1}\")\n",
    "            continue\n",
    "\n",
    "        # Case 2: shapes differ ‚Üí compare overlapping pruned slices\n",
    "        mask_layer = find_mask_layer(module_name, masks)\n",
    "        if mask_layer:\n",
    "            mask = masks[mask_layer]\n",
    "\n",
    "            # For Conv2d weight: [out, in, k, k]\n",
    "            if p1.ndim == 4:\n",
    "                parent = find_parent_for_compare(name1, masks)\n",
    "                if parent in masks:\n",
    "                    parent_mask = masks[parent]\n",
    "                    slice1 = p1[mask][:, parent_mask]\n",
    "                    slice2 = p2\n",
    "                else:\n",
    "                    slice1 = p1[mask]\n",
    "                    slice2 = p2\n",
    "\n",
    "            # For BN: weight, bias, running_mean, running_var\n",
    "            elif p1.ndim == 1:\n",
    "                slice1 = p1[mask]\n",
    "                slice2 = p2\n",
    "\n",
    "            else:\n",
    "                slice1 = None\n",
    "\n",
    "            if slice1 is not None and slice1.shape == slice2.shape:\n",
    "                equal = torch.allclose(slice1, slice2, atol=atol)\n",
    "                if equal:\n",
    "                    same.append(name1)\n",
    "                    if verbose: print(f\"‚úî SAME (pruned slice): {name1}\")\n",
    "                else:\n",
    "                    diffs.append(name1)\n",
    "                    if verbose: print(f\"‚ùå DIFF (pruned slice): {name1}\")\n",
    "            else:\n",
    "                shape_diffs.append((name1, slice1.shape if slice1 is not None else None, p2.shape))\n",
    "                if verbose:\n",
    "                    print(f\"‚ùå SHAPE DIFF (slice mismatch): {name1}\")\n",
    "        else:\n",
    "            # Non-pruned layer but shapes differ ‚Üí warn\n",
    "            shape_diffs.append((name1, p1.shape, p2.shape))\n",
    "            if verbose:\n",
    "                print(f\"‚ùå SHAPE DIFF (non-pruned): {name1}\")\n",
    "\n",
    "    print(\"\\n================ SUMMARY ================\")\n",
    "    print(f\"‚úî Identical (full or pruned slice): {len(same)}\")\n",
    "    print(f\"‚ùå Weight diffs:                   {len(diffs)}\")\n",
    "    print(f\"‚ùå Shape diffs:                    {len(shape_diffs)}\")\n",
    "    print(\"=========================================\\n\")\n",
    "\n",
    "    return {\n",
    "        \"same\": same,\n",
    "        \"diffs\": diffs,\n",
    "        \"shape_diffs\": shape_diffs\n",
    "    }\n",
    "\n",
    "\n",
    "def find_parent_for_compare(name, masks):\n",
    "    parts = name.split(\".\")\n",
    "    # try to detect ‚Äúprevious conv‚Äù inside DoubleConv\n",
    "    if parts[-1].isdigit():\n",
    "        idx = int(parts[-1])\n",
    "        if idx > 0:\n",
    "            parts[-1] = str(idx - 1)\n",
    "            parent = \".\".join(parts)\n",
    "            if parent in masks:\n",
    "                return parent\n",
    "    return None\n",
    "\n",
    "def find_mask_layer(module_name, masks):\n",
    "    \"\"\"\n",
    "    Map parameter or BN layer to the correct Conv2d mask.\n",
    "    Example:\n",
    "        decoders.9.net.1.weight ‚Üí decoders.9.net.0\n",
    "        decoders.9.net.4.bias   ‚Üí decoders.9.net.3\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Direct hit (Conv2d layer)\n",
    "    if module_name in masks:\n",
    "        return module_name\n",
    "\n",
    "    # 2. BN layer ‚Üí previous Conv2d (idx - 1)\n",
    "    parts = module_name.split(\".\")\n",
    "    if parts[-1].isdigit():\n",
    "        idx = int(parts[-1])\n",
    "        if idx > 0:\n",
    "            prev_name = \".\".join(parts[:-1] + [str(idx - 1)])\n",
    "            if prev_name in masks:\n",
    "                return prev_name\n",
    "\n",
    "    # 3. No associated mask\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "summary = compare_models_pruned(model, pruned_model, masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d1be91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7209a5bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnunet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
